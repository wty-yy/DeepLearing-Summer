{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cd2187a",
   "metadata": {},
   "source": [
    "# Part 1: Introduct to TensorFlow\n",
    "\n",
    "## 0.1 Install TensorFlow\n",
    "这部分介绍TensorFlow的基本操作.\n",
    "\n",
    "启用TensorFlow，如果直接用 `pip install tensorflow` 默认安装的就是cpu版本的，安装GPU版本的 `pip install tensorflow-gpu`，使用Anaconda可以将 `pip` 换为 `conda` 或 `mamba` 进行安装.\n",
    "\n",
    "还需使用 `mitdeeplearning` 相关库文件，需要三步操作：\n",
    "\n",
    "1. 执行 `pip install mitdeeplearning`.\n",
    "\n",
    "2. 到 [github - introtodeeplearning](https://github.com/aamini/introtodeeplearning) 下载该项目，解压后，到该目录下找到 `setup.py` 文件，使用命令行 `python setup.py install` 对其进行安装\n",
    "\n",
    "3. 完成相关包的补全. 先运行代码，看是否报错，如果报错看缺少哪个包就装哪个. 例如我就缺少 `cv2` 这个包，需要 `pip installl opencv-python`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1302d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensoFlow Version: 2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import mitdeeplearning as mdl\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print('TensoFlow Version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd7ca9a",
   "metadata": {},
   "source": [
    "## 1.1 Why TensorFlow called TensorFlow?\n",
    "\n",
    "TensorFlow之所以称为TensorFlow是因为它是以**流式处理**(Flow)张量数据类型(Tensors)，tensor是TensorFlow中的基础数据类型，它本质就是一种高维的数组.\n",
    "\n",
    "定义：**每一维内数据的形状是相同的，并且元素具有相同的数据类型**的数组，称为tensor-like.\n",
    "\n",
    "`np.ndarray` 就是一种 `tensor-like` 数据类型，数组中元素的数据类型可以是 `string` 或 `int` 或 `float` 等等.\n",
    "\n",
    "`Tensor` 类支持与 `np.ndarray` 类的相互转换.\n",
    "\n",
    "- `tensor.nupmy()` 将 `Tensor` 转为 `np.ndarray`.\n",
    "\n",
    "- `tf.constant(value)`：其中 `value` 为 `tensor-like` 对象（就是满足张量性质的），可以将 `np.ndarray` 转为**常量类型**的 `tensor`.\n",
    "\n",
    "- `tf.Variable(value)`：与 `tf.constant(value)` 完全一致，只是返回**变量类型**的 `tensor`.\n",
    "\n",
    "其实就是将向量($n\\times 1$)，矩阵($n\\times m$)泛化到更高维度，可以理解为“堆叠”.\n",
    "\n",
    "- 如三维就是矩阵的堆叠($k\\times n\\times m$)，就是 $k$ 个$ nxm$ 的矩阵的堆叠.\n",
    "\n",
    "Tensor最根本的性质就是形状(`shape`)，也就是Tensor在每一维上的大小，`rank`表示Tensor的维数 $n$，我们以后将 $n$ 维张量简记为 n-d Tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39d322b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# tensor和np.ndarray相互转换\n",
    "array = np.array([1, 2, 3])\n",
    "tensor = tf.constant(array)\n",
    "var_tensor = tf.Variable(array)\n",
    "print(type(tensor))\n",
    "print(type(var_tensor))\n",
    "print(type(tensor.numpy()))\n",
    "print(type(var_tensor.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a73ecb",
   "metadata": {},
   "source": [
    "首先看看标量(scalar)，也就是 0-d Tensor.\n",
    "\n",
    "- `tf.rank(tensor)`：返回 `tensor` 的 `rank` 值.\n",
    "\n",
    "- `tf.shape(tensor)`：返回 `tensor` 的 `shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c1d0fc2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'sport' is a 0-d Tensor\n",
      "'number' is a 0-d Tensor\n"
     ]
    }
   ],
   "source": [
    "sport = tf.constant('Badminton')\n",
    "number = tf.constant(3.1415926)\n",
    "print(\"'sport' is a {}-d Tensor\".format(tf.rank(sport)))\n",
    "print(\"'number' is a {}-d Tensor\".format(tf.rank(number)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d00189",
   "metadata": {},
   "source": [
    "向量(Vectors)为 1-d Tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f495d472",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'sport' is a 1-d Tensor with shape: [2]\n",
      "'number' is a 1-d Tensor with shape: [3]\n"
     ]
    }
   ],
   "source": [
    "sport = tf.constant(['Badminton', 'Tennis'])\n",
    "number = tf.constant([3.1415926, 1.414213, 2.71821])\n",
    "print(\"'sport' is a {}-d Tensor with shape: {}\".format(tf.rank(sport), tf.shape(sport)))\n",
    "print(\"'number' is a {}-d Tensor with shape: {}\".format(tf.rank(number), tf.shape(number)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47342218",
   "metadata": {},
   "source": [
    "矩阵(Matrix)为 2-d Tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2c9c39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'matrix' is a 2-d Tensor with shape: [3 3]\n"
     ]
    }
   ],
   "source": [
    "matrix = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(\"'matrix' is a {}-d Tensor with shape: {}\".format(tf.rank(matrix), tf.shape(matrix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e797b3ba",
   "metadata": {},
   "source": [
    "3-d Tensor，可以表示一张RGB三通道图片.\n",
    "\n",
    "- `tf.zeros(shape)`：`shape` 一个由整数构成的向量，可以是list, tuple, 1-d Tensor 数据类型，返回一个元素全部为 $0$ 的形状满足 `shape` 要求的 tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df04dfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'image' is a 3-d Tensor with shape: [256 256   3]\n"
     ]
    }
   ],
   "source": [
    "image = tf.zeros([256, 256, 3])  # 256*256 像素的3通道图片\n",
    "print(\"'image' is a {}-d Tensor with shape: {}\".format(tf.rank(image), tf.shape(image)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98302325",
   "metadata": {},
   "source": [
    "4-d Tensor，可以表示多张RGB三通道图片."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a8461da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'images' is a 4-d Tensor with shape: [ 10 256 256   3]\n"
     ]
    }
   ],
   "source": [
    "images = tf.zeros([10, 256, 256, 3])  # 10张256*256 像素的3通道图片\n",
    "print(\"'images' is a {}-d Tensor with shape: {}\".format(tf.rank(images), tf.shape(images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddfb11a",
   "metadata": {},
   "source": [
    "与 `np.ndarray` 一样，我们可以对tensor取切片(slicing). 重新修改大小\n",
    "\n",
    "- `tf.reshape(tensor, shape)`：将 `tensor` 中的元素重新顺次排列为 `shape` 的形式. 需要保证 `shape` 的大小和 `tensor` 的元素个数相同. 当 `shape` 中有 `-1` 时，表示根据原 `tensor` 的元素个数自动计算补全该维度."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b533035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10 256  10   3]\n",
      "[     1      2      3 327680]\n"
     ]
    }
   ],
   "source": [
    "print(tf.shape(images[:, :, 0:10, :]).numpy())\n",
    "print(tf.shape(tf.reshape(images, [1, 2, 3, -1])).numpy())  # 最后一个维度的元素个数为自动计算的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaa5f9f",
   "metadata": {},
   "source": [
    "## 1.2 Computations on Tensors\n",
    "\n",
    "TensorFlow主要计算tensors之间的运算，本质也就是创建一个计算图(Computation Graph)，它是由tensors之间的运算关系构成的边，tensors构成的点，下面是一个简单的例子.\n",
    "\n",
    "- `tf.add(tensor1, tensor2)`：\n",
    "\n",
    "![](./img/add-graph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "016e96b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(35, shape=(), dtype=int32)\n",
      "tf.Tensor(35, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(15)\n",
    "b = tf.constant(20)\n",
    "\n",
    "c1 = tf.add(a, b)\n",
    "c2 = a + b  # 和 tf.add 具有相同的效果\n",
    "print(c1, c2, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fe6a13",
   "metadata": {},
   "source": [
    "当我们创建一个计算图时，它是一个计算关系，而不一定直接对变量进行计算，需要代值进行计算（即函数），例如下面这个例子：\n",
    "![](./img/computation-graph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24b5bddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(a, b):\n",
    "    c = a + b\n",
    "    d = b - 1\n",
    "    e = c * d\n",
    "    return e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5fe28f",
   "metadata": {},
   "source": [
    "接下来通过调用该函数，从而使用输入的 `a, b` 执行该计算图."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22cc3fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "source": [
    "a, b = 1.5, 2.5\n",
    "e_out = func(a, b)\n",
    "print(e_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c73080",
   "metadata": {},
   "source": [
    "## 1.3 Neual networks in TensorFlow\n",
    "\n",
    "我们可以进一步在TensorFlow中定义神经网络，TensorFlow使用Keras这个高级API，用于搭建和训练神经网络模型.\n",
    "\n",
    "我们先考虑一个简单的感知器(perceptron)，通过一个紧密层 $y=\\sigma(Wx+b)$，其中 $W$ 为权重矩阵(matrix of weights)，$b$ 为偏置(bias)，$x$ 为输入(input)，$\\sigma$ 为sigmoid激活函数(activation function)，$y$ 为输出(output). 计算图如下图所示：\n",
    "\n",
    "![perceptron](./img/computation-graph-2.png)\n",
    "\n",
    "tensors可以通过layers进行流式传播，layers也就是神经网络的基本模块. layers是神经网络中的基本操作，用于**更新权重，计算losses，定义层之间的联机**. 我们从定义一个 `layer` 来实现上述的perceptron.\n",
    "\n",
    "实现方式为通过继承 `tf.keras.layers.Layer` 对象，其需要包含以下的方法:\n",
    "\n",
    "- `__init__(self, *args)`：定义自定义层的属性，如设定输出的维数；并调用 `super().__init__()` 执行父类的初始化方法.\n",
    "\n",
    "- `build(self, input_shape)`：该方法用于创建与改layer相关的权重变量，利用 `self.add_weight()` 可以为当前层添加权重变量.\n",
    "  `add_weight(name=None, shape=None, ...)`：父类的方法，`name` 为该权重变量的名称，`shape` 为该权重变量的形状.\n",
    "\n",
    "- `call(self, inputs, *args, **kwargs)`： 构建计算图，在 `build()` 定义后进行定义，当调用 `__call__` （也就是将类作为函数进行调用）时会调用该函数.\n",
    "\n",
    "这里推荐使用Pycharm写核心代码然后用 `load \"filename.py\"` 将文件加载到Jupyter中，效率更高.\n",
    "\n",
    "使用CPU版本tensorflow就不会报错，而使用GPU版本的tensorflow则会报错了，但是误差非常的小，应该是判断的精度上有些错误."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa2a68c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.26978594 0.45750415 0.66536945]]\n",
      "[PASS] test_custom_dense_layer_output\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load \"Custom Dense Layer.py\"\n",
    "\n",
    "### Defining a network Layer ###\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "# n_output_nodes: number of output nodes\n",
    "# input_shape: shape of the input\n",
    "# x: input to the layer\n",
    "\n",
    "class OurDenseLayer(layers.Layer):\n",
    "    def __init__(self, n_output_nodes):  # defines custom layer attributes\n",
    "        super().__init__()\n",
    "        self.W, self.b = None, None\n",
    "        self.n_output_nodes = n_output_nodes\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        d = int(input_shape[-1])  # input_shape dimensionality\n",
    "        self.W = self.add_weight('weight', [d, self.n_output_nodes])  # matrix of weights\n",
    "        self.b = self.add_weight('bias', [1, self.n_output_nodes])  # bias\n",
    "\n",
    "    def call(self, x):  # set computation graph\n",
    "        x = tf.cast(x, tf.float32)  # tensor之间的运算必须为 tf.float32 数据类型\n",
    "        z = x @ self.W + self.b\n",
    "        y = keras.activations.sigmoid(z)\n",
    "        return y\n",
    "\n",
    "# Since layers parameters are initialized randomly, we will set a random seed for reproducibility\n",
    "tf.random.set_seed(1)\n",
    "layer = OurDenseLayer(3)\n",
    "layer.build((1,2))\n",
    "x_input = tf.constant([[1,2]])\n",
    "y = layer.call(x_input)\n",
    "\n",
    "# test the output!\n",
    "print(y.numpy())\n",
    "mdl.lab1.test_custom_dense_layer_output(y)\n",
    "#layer.W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad99067",
   "metadata": {},
   "source": [
    "上述全连接层可以用一个 `tf.keras.layers.Dense` 等价实现\n",
    "\n",
    "- `tf.keras.layers.Dense(units, input_shape=(n, m))`：`units` 为该全连接层的神经元个数，`input_shape` 为输入张量的形状."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7069be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.5607363  0.65668976 0.12496966]], shape=(1, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "dense_layer = layers.Dense(3, activation='sigmoid')  # OurDenseLayer 的等价形式\n",
    "print(dense_layer(x_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7558e526",
   "metadata": {},
   "source": [
    "使用 `tf.keras.Sequential` 还可以对多个 `layer` 进行堆叠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "062e7c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_output: [[ 0.62118787 -0.08692831  1.6387595 ]]\n"
     ]
    }
   ],
   "source": [
    "### Defining a neural network using the Sequential API ###\n",
    "\n",
    "\n",
    "# Define the number of outputs\n",
    "n_output_nodes = 3\n",
    "\n",
    "# First define the model \n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "'''TODO: Define a dense (fully connected) layer to compute z'''\n",
    "# Remember: dense layers are defined by the parameters W and b!\n",
    "# You can read more about the initialization of W and b in the TF documentation :) \n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense?version=stable\n",
    "dense_layer = layers.Dense(n_output_nodes)\n",
    "\n",
    "# Add the dense layer to the model\n",
    "model.add(dense_layer)\n",
    "    \n",
    "# Test model with example input\n",
    "x_input = tf.constant([[1,2.]], shape=(1,2))\n",
    "\n",
    "'''TODO: feed input into the model and predict the output!'''\n",
    "model_output = model(x_input)\n",
    "print(f\"model_output: {model_output.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e23f22d",
   "metadata": {},
   "source": [
    "类似的也可以自定义Model，通过继承 [`tf.keras.Model`](https://tensorflow.google.cn/api_docs/python/tf/keras/Model?hl=en)，只需实现两个函数 `__init__` 初始化和 `call` 执行模型函数. 自定义一个带有 `isidentity` 参数的Model，若 `isidentity=True` 则直接返回输入变量，否则返回经过一个全连接层的结果."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4d3ad67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network output with activation: [[0.29996255 0.62776643 0.48460072]];\n",
      "Network identity output: [[1. 2.]]\n"
     ]
    }
   ],
   "source": [
    "class IdentityModel(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.dense_layer = layers.Dense(units, activation='sigmoid')\n",
    "    \n",
    "    def call(self, inputs, isidentity=False):\n",
    "        x = self.dense_layer(inputs)\n",
    "        if isidentity:\n",
    "            return inputs\n",
    "        return x\n",
    "\n",
    "n_output_nodes = 3\n",
    "model = IdentityModel(n_output_nodes)\n",
    "\n",
    "x_input = tf.constant([[1,2.]], shape=(1,2))\n",
    "out_activate = model(x_input)\n",
    "out_identity = model(x_input, isidentity=True)\n",
    "\n",
    "print(f\"Network output with activation: {out_activate};\\nNetwork identity output: {out_identity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b162c77a",
   "metadata": {},
   "source": [
    "## 1.4 Automatic differentiation in TensorFlow\n",
    "\n",
    "自动微分是TensorFlow中非常重要的一部分，用于反向传播时使用梯度下降法对可学习参数进行更新，从而减小loss值，下面是一个例子（来源神经网络与深度学习 邱锡鹏 P97）\n",
    "![神经网络与深度学习 邱锡鹏 P97](./img/神经网络与深度学习-邱锡鹏.png)\n",
    "\n",
    "其实就是可以实现程序自动求导的过程，把计算式展开成一个带状，然后利用链式法则，从后到前逐项求导（求梯度），所以形象称为Gradient Tape. 下面让我们试试TensorFlow中的自动微分功能 [`tf.GradientTape`](https://www.tensorflow.org/api_docs/python/tf/GradientTape?version=stable).\n",
    "\n",
    "比如我们要求 $y = \\frac{1}{x^2}$ 在 $x = 2$ 处的导数值 $y'(2) = -\\frac{1}{4}$，使用方法如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "380cc692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy_dx: -0.25\n"
     ]
    }
   ],
   "source": [
    "### Gradient computation with GradientTape ###\n",
    "# y = 1/(x^2)\n",
    "x = tf.Variable(2.)\n",
    "\n",
    "# initiate a gradient tape\n",
    "with tf.GradientTape() as tape:\n",
    "    # Define the function\n",
    "    y = 1 / x ** 2\n",
    "# Access the gradient -- derivative of y with respect to x（y 对 x 的导数）\n",
    "dy_dx = tape.gradient(y, x)\n",
    "print(f\"dy_dx: {dy_dx.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792bb685",
   "metadata": {},
   "source": [
    "当我们进行神经网络训练时，可以视为最小化损失函数 $\\mathcal{L(y, \\hat{y})}$ 的最优化问题，将每个可学习参数都对Loss函数求梯度，然后使用随机梯度下降法(stochastic gradient descent, SGD)，对可学习参数在负梯度方向乘上学习因子 $\\mu$ 进行更新. 也就是，设 $W$ 为可学习参数，则每次更新为 $W' = W - \\mu \\cdot \\frac{\\partial L}{\\partial W}$.\n",
    "\n",
    "比如我们现在的可学习参数为 $x$，Loss函数为 $\\mathcal{L} = (x - y)^2$，其中 $y$ 是一个常量. 显然当 $x=y$ 时，$\\mathcal{L}$ 有最小值 $0$，下面让我们梯度下降法对其进行求解.\n",
    "\n",
    "下面代码中有一个细节，由于求梯度必须要求变量为 `tf.Variable` 类，而 `tf.Variable` 有一种特殊的赋值方法 `tf.Variable.assign(value)` 可以将变量赋值为 `value` 且还能保持为 `tf.Variable` 类，等价于 `x = tf.Variable(value)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85cb473f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing x=[[-1.1771783]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Function minimization with automatic differentiation and SGD ###\n",
    "\n",
    "# Initialize a random value for out initial x\n",
    "x = tf.Variable([tf.random.normal([1])])  # Outputs random values from a normal distribution\n",
    "print(f\"Initializing x={x.numpy()}\")\n",
    "\n",
    "learning_rate = 1e-2  # learning rate for SGD\n",
    "history = []  # memory the change of x\n",
    "# Define the target value\n",
    "y = 4\n",
    "\n",
    "# We will run SGD for a number of iterations. At each iteration, we compute the loss,\n",
    "# compute the derivative of the loss with respect to x, and perform the SGD update.\n",
    "for i in range(500):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = (x - y) ** 2\n",
    "    grad = tape.gradient(loss, x)  # comput the derivative of the loss with respect to x\n",
    "    x.assign(x - learning_rate * grad)  # update the value of x\n",
    "    #x = x - learning_rate * grad  # can't use it, it will change x to tf.constant but not tf.Variable\n",
    "    history.append(x.numpy()[0])\n",
    "    \n",
    "# Plot the evolution of x as we optimize towards y!\n",
    "plt.plot(history, label='Predicted')\n",
    "plt.plot([0, 500], [y, y], label='True')\n",
    "plt.legend()\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('x value')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
